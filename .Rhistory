return(ifelse(g1 * g2 > alpha, 1, data$A2))
} else {
return(data[[trt]])  # For any other variable, return as is
}
}
# Run analysis
data<-as.data.frame(data)
result_dynamic <- lmtp_tmle(
data = data,
trt = c("A1", "A2"),
outcome = c("Y2", "Y3"),
time_vary = list("L1", "L2"),
shift = dynamic_threshold_shift,
mtp = TRUE,
outcome_type = "survival",
folds = 5,
learners_trt = c("SL.glm"),
learners_outcome = c("SL.glm")
)
print(result_dynamic)
dynamic_threshold_shift <- function(data, trt) {
# Ensure data is a data frame
data <- as.data.frame(data)
n <- nrow(data)
# Compute propensity scores
tryCatch({
fit1 <- glm(A1 ~ L1, data = data, family = binomial())
g1 <- predict(fit1, type = "response")
fit2 <- glm(A2 ~ L1 + A1 + L2, data = data, family = binomial())
g2 <- predict(fit2, type = "response")
}, error = function(e) {
cat("Error in propensity score estimation:", e$message, "\n")
return(data[[trt]])  # Return natural values on error
})
# Apply intervention
if (trt == "A1") {
return(ifelse(g1 > alpha, 1, data$A1))
} else if (trt == "A2") {
#return(ifelse(data$A1*g1 * g2 > alpha, 1, data$A2))
return(ifelse(g1 * g2 > alpha, 1, data$A2))
} else {
return(data[[trt]])  # For any other variable, return as is
}
}
# Run analysis
data<-as.data.frame(data)
result_dynamic <- lmtp_tmle(
data = data,
trt = c("A1", "A2"),
outcome = c("Y2", "Y3"),
time_vary = list("L1", "L2"),
shift = dynamic_threshold_shift,
mtp = TRUE,
outcome_type = "survival",
folds = 5,
learners_trt = c("SL.glm"),
learners_outcome = c("SL.glm")
)
print(result_dynamic)
dynamic_threshold_shift <- function(data, trt) {
# Ensure data is a data frame
data <- as.data.frame(data)
n <- nrow(data)
# Compute propensity scores
tryCatch({
fit1 <- glm(A1 ~ L1, data = data, family = binomial())
g1 <- predict(fit1, type = "response")
fit2 <- glm(A2 ~ L1 + A1 + L2, data = data, family = binomial())
g2 <- predict(fit2, type = "response")
}, error = function(e) {
cat("Error in propensity score estimation:", e$message, "\n")
return(data[[trt]])  # Return natural values on error
})
# Apply intervention
if (trt == "A1") {
return(ifelse(g1 > alpha, 1, data$A1))
} else if (trt == "A2") {
#return(ifelse(data$A1*g1 * g2 > alpha, 1, data$A2))
return(ifelse(g1 * g2 > alpha, 1, data$A2))
} else {
return(data[[trt]])  # For any other variable, return as is
}
}
# Run analysis
data<-as.data.frame(data)
result_dynamic <- lmtp_tmle(
data = data,
trt = c("A1", "A2"),
outcome = c("Y2", "Y3"),
time_vary = list("L1", "L2"),
shift = dynamic_threshold_shift,
mtp = TRUE,
outcome_type = "survival",
folds = 5,
learners_trt = c("SL.glm"),
learners_outcome = c("SL.glm")
)
print(result_dynamic)
dynamic_threshold_shift <- function(data, trt) {
# Ensure data is a data frame
data <- as.data.frame(data)
n <- nrow(data)
# Compute propensity scores
tryCatch({
fit1 <- glm(A1 ~ L1, data = data, family = binomial())
g1 <- predict(fit1, type = "response")
fit2 <- glm(A2 ~ L1 + A1 + L2, data = data, family = binomial())
g2 <- predict(fit2, type = "response")
}, error = function(e) {
cat("Error in propensity score estimation:", e$message, "\n")
return(data[[trt]])  # Return natural values on error
})
# Apply intervention
if (trt == "A1") {
return(ifelse(g1 > alpha, 1, data$A1))
} else if (trt == "A2") {
#return(ifelse(data$A1*g1 * g2 > alpha, 1, data$A2))
return(ifelse(g1 * g2 > alpha, 1, data$A2))
} else {
return(data[[trt]])  # For any other variable, return as is
}
}
# Run analysis
data<-as.data.frame(data)
result_dynamic <- lmtp_tmle(
data = data,
trt = c("A1", "A2"),
outcome = c("Y2", "Y3"),
time_vary = list("L1", "L2"),
shift = dynamic_threshold_shift,
mtp = TRUE,
outcome_type = "survival",
folds = 5,
learners_trt = c("SL.glm"),
learners_outcome = c("SL.glm")
)
print(result_dynamic)
dynamic_threshold_shift <- function(data, trt) {
# Ensure data is a data frame
data <- as.data.frame(data)
n <- nrow(data)
# Compute propensity scores
tryCatch({
fit1 <- glm(A1 ~ L1, data = data, family = binomial())
g1 <- predict(fit1, type = "response")
fit2 <- glm(A2 ~ L1 + A1 + L2, data = data, family = binomial())
g2 <- predict(fit2, type = "response")
}, error = function(e) {
cat("Error in propensity score estimation:", e$message, "\n")
return(data[[trt]])  # Return natural values on error
})
# Apply intervention
if (trt == "A1") {
return(ifelse(g1 > alpha, 1, data$A1))
} else if (trt == "A2") {
return(ifelse(data$A1*g1 * g2 > alpha, 1, data$A2))
#return(ifelse(g1 * g2 > alpha, 1, data$A2))
} else {
return(data[[trt]])  # For any other variable, return as is
}
}
# Run analysis
data<-as.data.frame(data)
result_dynamic <- lmtp_tmle(
data = data,
trt = c("A1", "A2"),
outcome = c("Y2", "Y3"),
time_vary = list("L1", "L2"),
shift = dynamic_threshold_shift,
mtp = TRUE,
outcome_type = "survival",
folds = 5,
learners_trt = c("SL.glm"),
learners_outcome = c("SL.glm")
)
print(result_dynamic)
library(lmtp)
library(data.table)
# Data generation function
genData <- function(n,p,intervene=NULL) {
# exogenous variables
for(i in 1:2){
assign(paste0("U.Lt",i), rnorm(n, mean=0, sd=1))
assign(paste0("U.At",i), rnorm(n,0,1))
assign(paste0("U.Yt",i+1), rnorm(n,0,1))
}
# endogenous variables
L1 = as.numeric(U.Lt1 < 0.4) #most people controlled at BL
if(is.null(intervene)){
A1 = as.numeric( U.At1+1 < plogis(L1))#people controlled/healthier more likely to go on GLP1
}else{
A1<-intervene
}
Y2 = as.numeric(U.Yt2 > plogis((L1+(A1*2))))#less people with tx+controlled L1 have outcome
L2 = ifelse(Y2==0, as.numeric(plogis(A1 + L1 + U.Lt2) > 0.4),0)#NA
if(is.null(intervene)){
A2 = ifelse(Y2==0,as.numeric(U.At2+1 < plogis((L2)+A1+L1)),A1)#NA
}else{
A2<-intervene
}
Y3 = ifelse(Y2==0, as.numeric(U.Yt3+1 < plogis(L1+A1+(L2)+A2)),1)#NA
# dataframe with endogenous variables
ObsData <- data.table(L1,A1,Y2,L2,A2,Y3)
return(ObsData)
}
# Generate data
set.seed(123)
data <- genData(n=1000, p=2, intervene=NULL)
alpha <- 0.1
#############################################################################
# UNDERSTANDING LMTP: KEY CONCEPTS
#
# 1. SHIFT FUNCTION: Defines your intervention POLICY (not assumptions)
# 2. BACKWARD SEQUENTIAL REGRESSION: How lmtp estimates the effect
# 3. DENSITY RATIOS: How incompatible histories are handled
#
# The shift function is called forward (A1, then A2) to define the policy,
# but estimation proceeds backward (from τ to 1) using sequential regression.
#############################################################################
# Shift function that computes propensity scores internally
dynamic_threshold_shift <- function(data, trt) {
# Ensure data is a data frame
data <- as.data.frame(data)
n <- nrow(data)
# Compute propensity scores
tryCatch({
fit1 <- glm(A1 ~ L1, data = data, family = binomial())
g1 <- predict(fit1, type = "response")
fit2 <- glm(A2 ~ L1 + A1 + L2, data = data, family = binomial())
g2 <- predict(fit2, type = "response")
}, error = function(e) {
cat("Error in propensity score estimation:", e$message, "\n")
return(data[[trt]])  # Return natural values on error
})
# Apply intervention
if (trt == "A1") {
return(ifelse(g1 > alpha, 1, data$A1))
} else if (trt == "A2") {
####################################################################
# TWO FUNDAMENTALLY DIFFERENT POLICIES
#
# Choose based on your research question!
####################################################################
# Policy 1: "Sequential adherence policy"
# --------------------------------------
# "Treat at time 2 if currently on treatment AND cumulative propensity > α"
# - Respects treatment continuity
# - More conservative/realistic for clinical protocols
# - Use when: treatment adherence matters
#
# return(ifelse(data$A1 * g1 * g2 > alpha, 1, data$A2))
# Policy 2: "Cumulative propensity policy" (CURRENTLY ACTIVE)
# ---------------------------------------
# "Treat at time 2 if cumulative propensity > α, regardless of current treatment"
# - Based purely on treatability scores
# - More aggressive/theoretical
# - Use when: you want optimal treatment based on propensity alone
#
return(ifelse(g1 * g2 > alpha, 1, data$A2))
####################################################################
# EXAMPLE: Why these policies differ
#
# Person with g1 = 0.4 > α, observed A1 = 0, g2 = 0.8, g1×g2 = 0.32 > α
# - Policy 1: A1 * g1 * g2 = 0 * 0.32 = 0 < α → A2 = natural value
# - Policy 2: g1 * g2 = 0.32 > α → A2 = 1
#
# Policy 2 says "treat" but this person gets weight ≈ 0 because
# their observed history (A1=0) is incompatible with the policy!
####################################################################
} else {
return(data[[trt]])  # For any other variable, return as is
}
}
####################################################################
# HOW LMTP HANDLES INCOMPATIBLE HISTORIES: THE DENSITY RATIO MECHANISM
#
# The key insight: g^d(at|ht) can be ZERO when history is incompatible!
#
# For deterministic policies like "treat if g1 > α":
# - If g1 > α: g^d(1|h) = 1, g^d(0|h) = 0
# - If g1 ≤ α: g^d(at|h) = g(at|h)
#
# The weight wt = g^d(at|ht) / g(at|ht) becomes:
#
# Compatible case (g1 > α, A1 = 1):
#   w1 = 1 / g1 > 1 (upweighted)
#
# Incompatible case (g1 > α, A1 = 0):
#   w1 = 0 / (1-g1) = 0 (zero weight!)
#
# Natural value case (g1 ≤ α):
#   w1 = g(at|h) / g(at|h) = 1
#
# The product ∏wt across time ensures any incompatibility → zero weight
####################################################################
# Run analysis
data <- as.data.frame(data)
result_dynamic <- lmtp_tmle(
data = data,
trt = c("A1", "A2"),
outcome = c("Y2", "Y3"),
time_vary = list("L1", "L2"),
shift = dynamic_threshold_shift,
mtp = TRUE,
outcome_type = "survival",
folds = 5,
learners_trt = c("SL.glm"),
learners_outcome = c("SL.glm")
)
print(result_dynamic)
####################################################################
# SUMMARY: THE COMPLETE PICTURE
#
# 1. YOUR SHIFT FUNCTION defines a policy (forward direction)
#
# 2. LMTP ESTIMATES the effect using:
#    - Backward sequential regression (τ to 1)
#    - Density ratios that can be zero for incompatible histories
#    - Product of weights that enforces compatibility
#
# 3. THE RESULT: Correct counterfactual effect for your chosen policy
#    - Incompatible observations get zero weight
#    - Compatible observations contribute appropriately
#    - Final estimate reflects world where everyone follows the policy
#
# Key insight: The density ratio isn't just reweighting - it's
# enforcing compatibility through zero weights when g^d = 0!
####################################################################
library(lmtp)
library(data.table)
# Data generation function
genData <- function(n,p,intervene=NULL) {
# exogenous variables
for(i in 1:2){
assign(paste0("U.Lt",i), rnorm(n, mean=0, sd=1))
assign(paste0("U.At",i), rnorm(n,0,1))
assign(paste0("U.Yt",i+1), rnorm(n,0,1))
}
# endogenous variables
L1 = as.numeric(U.Lt1 < 0.4) #most people controlled at BL
if(is.null(intervene)){
A1 = as.numeric( U.At1+1 < plogis(L1))#people controlled/healthier more likely to go on GLP1
}else{
A1<-intervene
}
Y2 = as.numeric(U.Yt2 > plogis((L1+(A1*2))))#less people with tx+controlled L1 have outcome
L2 = ifelse(Y2==0, as.numeric(plogis(A1 + L1 + U.Lt2) > 0.4),0)#NA
if(is.null(intervene)){
A2 = ifelse(Y2==0,as.numeric(U.At2+1 < plogis((L2)+A1+L1)),A1)#NA
}else{
A2<-intervene
}
Y3 = ifelse(Y2==0, as.numeric(U.Yt3+1 < plogis(L1+A1+(L2)+A2)),1)#NA
# dataframe with endogenous variables
ObsData <- data.table(L1,A1,Y2,L2,A2,Y3)
return(ObsData)
}
# Generate data
set.seed(123)
data <- genData(n=1000, p=2, intervene=NULL)
alpha <- 0.1
#############################################################################
# UNDERSTANDING LMTP: KEY CONCEPTS
#
# 1. SHIFT FUNCTION: Defines your intervention POLICY (not assumptions)
# 2. BACKWARD SEQUENTIAL REGRESSION: How lmtp estimates the effect
# 3. DENSITY RATIOS: How incompatible histories are handled
#
# The shift function is called forward (A1, then A2) to define the policy,
# but estimation proceeds backward (from τ to 1) using sequential regression.
#############################################################################
# Shift function that computes propensity scores internally
dynamic_threshold_shift <- function(data, trt) {
# The Mark and Maya's proposal implementation
# Allow the intervention skip in the "very unlikeliy to intervene" time point
# if (trt == "A1") {
#   return(ifelse(g1 > alpha, 1, data$A1))
# } else if (trt == "A2") {
#   cum_prod_hist=1
#   if(cum_prod_hist*g1 > alpha){
#     cum_prod_hist=cum_prod_hist*g1
#   }
#   return(ifelse(g2*cum_prod_hist>alpha,1,data$A2))
# }else if (trt == "A3") {
#   cum_prod_hist=1
#
#   if(cum_prod_hist*g1 > alpha){
#     cum_prod_hist=cum_prod_hist*g1
#   }esle{
#     cum_prod_hist=cum_prod_hist
#   }
#
#   if(cum_prod_hist*g2 > alpha){
#     cum_prod_hist=cum_prod_hist*g2
#   }esle{
#     cum_prod_hist=cum_prod_hist
#   }
#
#   return(ifelse(g3*cum_prod_hist>alpha,1,data$A3))
# }
#
#
#
# Ensure data is a data frame
data <- as.data.frame(data)
n <- nrow(data)
# Compute propensity scores
tryCatch({
fit1 <- glm(A1 ~ L1, data = data, family = binomial())
g1 <- predict(fit1, type = "response")
fit2 <- glm(A2 ~ L1 + A1 + L2, data = data, family = binomial())
g2 <- predict(fit2, type = "response")
}, error = function(e) {
cat("Error in propensity score estimation:", e$message, "\n")
return(data[[trt]])  # Return natural values on error
})
# Apply intervention
if (trt == "A1") {
return(ifelse(g1 > alpha, 1, data$A1))
} else if (trt == "A2") {
####################################################################
# TWO FUNDAMENTALLY DIFFERENT POLICIES
#
# Choose based on your research question!
####################################################################
# Policy 1: "Sequential adherence policy"
# --------------------------------------
# "Treat at time 2 if currently on treatment AND cumulative propensity > α"
# - Respects treatment continuity
# - More conservative/realistic for clinical protocols
# - Use when: treatment adherence matters
#
# return(ifelse(data$A1 * g1 * g2 > alpha, 1, data$A2))
# Policy 2: "Cumulative propensity policy" (CURRENTLY ACTIVE)
# ---------------------------------------
# "Treat at time 2 if cumulative propensity > α, regardless of current treatment"
# - Based purely on treatability scores
# - More aggressive/theoretical
# - Use when: you want optimal treatment based on propensity alone
#
return(ifelse(g1 * g2 > alpha, 1, data$A2))
####################################################################
# EXAMPLE: Why these policies differ
#
# Person with g1 = 0.4 > α, observed A1 = 0, g2 = 0.8, g1×g2 = 0.32 > α
# - Policy 1: A1 * g1 * g2 = 0 * 0.32 = 0 < α → A2 = natural value
# - Policy 2: g1 * g2 = 0.32 > α → A2 = 1
#
# Policy 2 says "treat" but this person gets weight ≈ 0 because
# their observed history (A1=0) is incompatible with the policy!
####################################################################
} else {
return(data[[trt]])  # For any other variable, return as is
}
}
####################################################################
# HOW LMTP HANDLES INCOMPATIBLE HISTORIES: THE DENSITY RATIO MECHANISM
#
# The key insight: g^d(at|ht) can be ZERO when history is incompatible!
#
# For deterministic policies like "treat if g1 > α":
# - If g1 > α: g^d(1|h) = 1, g^d(0|h) = 0
# - If g1 ≤ α: g^d(at|h) = g(at|h)
#
# The weight wt = g^d(at|ht) / g(at|ht) becomes:
#
# Compatible case (g1 > α, A1 = 1):
#   w1 = 1 / g1 > 1 (upweighted)
#
# Incompatible case (g1 > α, A1 = 0):
#   w1 = 0 / (1-g1) = 0 (zero weight!)
#
# Natural value case (g1 ≤ α):
#   w1 = g(at|h) / g(at|h) = 1
#
# The product ∏wt across time ensures any incompatibility → zero weight
####################################################################
# Run analysis
data <- as.data.frame(data)
result_dynamic <- lmtp_tmle(
data = data,
trt = c("A1", "A2"),
outcome = c("Y2", "Y3"),
time_vary = list("L1", "L2"),
shift = dynamic_threshold_shift,
mtp = TRUE,
outcome_type = "survival",
folds = 5,
learners_trt = c("SL.glm"),
learners_outcome = c("SL.glm")
)
print(result_dynamic)
####################################################################
# SUMMARY: THE COMPLETE PICTURE
#
# 1. YOUR SHIFT FUNCTION defines a policy (forward direction)
#
# 2. LMTP ESTIMATES the effect using:
#    - Backward sequential regression (τ to 1)
#    - Density ratios that can be zero for incompatible histories
#    - Product of weights that enforces compatibility
#
# 3. THE RESULT: Correct counterfactual effect for your chosen policy
#    - Incompatible observations get zero weight
#    - Compatible observations contribute appropriately
#    - Final estimate reflects world where everyone follows the policy
#
# Key insight: The density ratio isn't just reweighting - it's
# enforcing compatibility through zero weights when g^d = 0!
####################################################################
result_dynamic$fits_r
result_dynamic$fits_m
